2023-12-21 10:16:32,058 [INFO ]  *** Training model from scratch ***
2023-12-21 10:16:32,058 [INFO ]  Machine name: titan
2023-12-21 10:16:32,058 [INFO ]  Arguments: 
2023-12-21 10:16:32,058 [INFO ]  Namespace(appliance_name='kettle', model_arch='transformer', datadir='./dataset_management/refit', save_dir='/home/lindo/Develop/nilm/ml/models', batchsize=512, n_epoch=50, crop_train_dataset=10000000, crop_val_dataset=None, do_not_use_distributed_training=False, resume_training=False, plot_display=False)
2023-12-21 10:16:32,058 [INFO ]  Window length: 599
2023-12-21 10:16:32,058 [INFO ]  Training dataset: ./dataset_management/refit/kettle/kettle_training_.csv
2023-12-21 10:16:32,058 [INFO ]  Validation dataset: ./dataset_management/refit/kettle/kettle_validation_H5.csv
2023-12-21 10:16:32,058 [INFO ]  Checkpoint file path: /home/lindo/Develop/nilm/ml/models/kettle/checkpoints_transformer
2023-12-21 10:16:32,058 [INFO ]  SaveModel file path: /home/lindo/Develop/nilm/ml/models/kettle/savemodel_transformer
2023-12-21 10:16:32,058 [INFO ]  Training history file path: /home/lindo/Develop/nilm/ml/models/kettle/history_transformer
2023-12-21 10:16:34,755 [INFO ]  There are 10.000M training samples.
2023-12-21 10:16:34,756 [INFO ]  There are 7.431M validation samples.
2023-12-21 10:16:34,756 [INFO ]  Normalized on power threshold: 0.6451612903225806
2023-12-21 10:16:34,756 [INFO ]  L1 loss multiplier: 1.0
2023-12-21 10:16:34,756 [INFO ]  Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
2023-12-21 10:16:34,916 [INFO ]  Number of replicas: 2.
2023-12-21 10:16:34,917 [INFO ]  Global batch size: 1024.
2023-12-21 10:16:35,296 [INFO ]  Learning rate: 0.0001
2023-12-21 10:16:36,931 [INFO ]  Collective all_reduce tensors: 44 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1
2023-12-21 10:16:38,331 [INFO ]  Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
2023-12-21 10:16:39,217 [INFO ]  Collective all_reduce tensors: 44 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1
2023-12-21 10:16:39,498 [INFO ]  Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
2023-12-21 10:16:45,707 [INFO ]  Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
2023-12-21 10:16:45,711 [INFO ]  Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
2023-12-21 10:16:45,715 [INFO ]  Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
2023-12-21 10:16:45,716 [INFO ]  Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
2023-12-21 10:16:45,938 [INFO ]  Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
2023-12-21 10:16:45,939 [INFO ]  Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
2023-12-21 10:16:45,940 [INFO ]  Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
2023-12-21 10:16:45,941 [INFO ]  Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
2023-12-21 10:52:48,992 [INFO ]  Running test loop after epoch: 1.
2023-12-21 11:04:36,637 [INFO ]  Current val loss of 0.1732 < than val loss of inf, saving model to /home/lindo/Develop/nilm/ml/models/kettle/savemodel_transformer.
2023-12-21 11:04:38,607 [INFO ]  Assets written to: /home/lindo/Develop/nilm/ml/models/kettle/savemodel_transformer/assets
2023-12-21 11:04:38,652 [INFO ]  epoch: 1 loss: 0.2754 mse: 0.02336 mae: 0.09872 val_loss: 0.1732 val_mse: 0.03767 val_mae: 0.129
2023-12-21 11:04:38,796 [INFO ]  Reshuffling training dataset.
2023-12-21 11:40:41,005 [INFO ]  Running test loop after epoch: 2.
2023-12-21 11:52:28,228 [INFO ]  epoch: 2 loss: 0.2214 mse: 0.02088 mae: 0.08261 val_loss: 0.1811 val_mse: 0.05306 val_mae: 0.1598
2023-12-21 11:52:28,409 [INFO ]  Reshuffling training dataset.
2023-12-21 12:28:32,067 [INFO ]  Running test loop after epoch: 3.
2023-12-21 12:40:19,059 [INFO ]  Current val loss of 0.1691 < than val loss of 0.1732, saving model to /home/lindo/Develop/nilm/ml/models/kettle/savemodel_transformer.
2023-12-21 12:40:21,146 [INFO ]  Assets written to: /home/lindo/Develop/nilm/ml/models/kettle/savemodel_transformer/assets
2023-12-21 12:40:21,198 [INFO ]  epoch: 3 loss: 0.2073 mse: 0.02093 mae: 0.0781 val_loss: 0.1691 val_mse: 0.04786 val_mae: 0.1565
2023-12-21 12:40:21,439 [INFO ]  Reshuffling training dataset.
2023-12-21 13:16:26,572 [INFO ]  Running test loop after epoch: 4.
2023-12-21 13:28:14,416 [INFO ]  epoch: 4 loss: 0.1937 mse: 0.02086 mae: 0.07431 val_loss: 0.1737 val_mse: 0.0351 val_mae: 0.1222
2023-12-21 13:28:14,704 [INFO ]  Reshuffling training dataset.
2023-12-21 14:04:19,966 [INFO ]  Running test loop after epoch: 5.
2023-12-21 14:16:08,225 [INFO ]  epoch: 5 loss: 0.1882 mse: 0.02029 mae: 0.07244 val_loss: 0.1925 val_mse: 0.05186 val_mae: 0.1459
2023-12-21 14:16:08,569 [INFO ]  Reshuffling training dataset.
2023-12-21 14:52:18,163 [INFO ]  Running test loop after epoch: 6.
2023-12-21 15:04:06,419 [INFO ]  epoch: 6 loss: 0.1833 mse: 0.01963 mae: 0.06985 val_loss: 0.1741 val_mse: 0.0414 val_mae: 0.1448
2023-12-21 15:04:06,846 [INFO ]  Reshuffling training dataset.
2023-12-21 15:40:15,698 [INFO ]  Running test loop after epoch: 7.
2023-12-21 15:52:04,355 [INFO ]  Current val loss of 0.164 < than val loss of 0.1691, saving model to /home/lindo/Develop/nilm/ml/models/kettle/savemodel_transformer.
2023-12-21 15:52:06,508 [INFO ]  Assets written to: /home/lindo/Develop/nilm/ml/models/kettle/savemodel_transformer/assets
2023-12-21 15:52:06,554 [INFO ]  epoch: 7 loss: 0.1774 mse: 0.0193 mae: 0.06754 val_loss: 0.164 val_mse: 0.02436 val_mae: 0.09075
2023-12-21 15:52:07,013 [INFO ]  Reshuffling training dataset.
2023-12-21 16:28:14,659 [INFO ]  Running test loop after epoch: 8.
2023-12-21 16:40:03,776 [INFO ]  epoch: 8 loss: 0.1752 mse: 0.01871 mae: 0.06558 val_loss: 0.1907 val_mse: 0.05197 val_mae: 0.16
2023-12-21 16:40:04,288 [INFO ]  Reshuffling training dataset.
2023-12-21 17:16:14,852 [INFO ]  Running test loop after epoch: 9.
2023-12-21 17:28:03,718 [INFO ]  epoch: 9 loss: 0.1728 mse: 0.01867 mae: 0.06484 val_loss: 0.1803 val_mse: 0.03392 val_mae: 0.1095
2023-12-21 17:28:04,293 [INFO ]  Reshuffling training dataset.
2023-12-21 18:04:15,449 [INFO ]  Running test loop after epoch: 10.
2023-12-21 18:16:04,833 [INFO ]  epoch: 10 loss: 0.1692 mse: 0.01812 mae: 0.06217 val_loss: 0.1742 val_mse: 0.03315 val_mae: 0.1092
2023-12-21 18:16:05,460 [INFO ]  Reshuffling training dataset.
2023-12-21 18:52:16,916 [INFO ]  Running test loop after epoch: 11.
2023-12-21 19:04:05,877 [INFO ]  epoch: 11 loss: 0.1681 mse: 0.01784 mae: 0.06118 val_loss: 0.1854 val_mse: 0.04695 val_mae: 0.1329
2023-12-21 19:04:06,551 [INFO ]  Reshuffling training dataset.
2023-12-21 19:40:19,084 [INFO ]  Running test loop after epoch: 12.
2023-12-21 19:52:08,115 [INFO ]  epoch: 12 loss: 0.1642 mse: 0.01774 mae: 0.05988 val_loss: 0.1794 val_mse: 0.03887 val_mae: 0.1161
2023-12-21 19:52:08,921 [INFO ]  Reshuffling training dataset.
2023-12-21 20:28:18,754 [INFO ]  Running test loop after epoch: 13.
2023-12-21 20:40:08,078 [INFO ]  epoch: 13 loss: 0.1631 mse: 0.01782 mae: 0.05974 val_loss: 0.169 val_mse: 0.03799 val_mae: 0.1205
2023-12-21 20:40:08,924 [INFO ]  Early termination of training.
2023-12-21 20:40:09,475 [INFO ]  Plot directory: /home/lindo/Develop/nilm/ml/models/kettle/train_transformer_loss
2023-12-21 20:40:09,793 [INFO ]  Plot directory: /home/lindo/Develop/nilm/ml/models/kettle/train_transformer_mae
